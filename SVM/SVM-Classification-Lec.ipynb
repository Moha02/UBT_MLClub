{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SVM - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UniversalBank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
       "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
       "       'CD Account', 'Online', 'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['CreditCard'], axis=1)\n",
    "\n",
    "y = df['CreditCard']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 13), (1000, 13))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy : 0.7490\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc=SVC() \n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "print('Model accuracy : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100.0 Model accuracy with rbf kernel : 0.6970\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(C=100.0) \n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "print('C=100.0 Model accuracy with rbf kernel : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0 Model accuracy with linear kernel : 0.7470\n"
     ]
    }
   ],
   "source": [
    "linear_svc=SVC(kernel='linear', C=1.0) \n",
    "linear_svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_test=linear_svc.predict(X_test)\n",
    "\n",
    "print('C=1.0 Model accuracy with linear kernel : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[696   8]\n",
      " [245  51]]\n",
      "\n",
      "True Positives(TP) =  696\n",
      "\n",
      "True Negatives(TN) =  51\n",
      "\n",
      "False Positives(FP) =  8\n",
      "\n",
      "False Negatives(FN) =  245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`~sklearn.svm.LinearSVC` or\n",
      " |  :class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy. The parameter is\n",
      " |      ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |  probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVR : Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC : Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See Also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluate the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  probA_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  probB_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |      Weights assigned to the features when `kernel=\"linear\"`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape (n_features, n_classes)\n",
      " |  \n",
      " |  n_support_\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
